import os
import requests
import json
import time
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables
env_path = r'd:\quicktoolshub\é›·è¾¾ç›‘æ§ã€‚\GRICH\grich-astro\.env'

# ç›´æ¥è¯»å–.envæ–‡ä»¶
env_vars = {}
try:
    with open(env_path, 'r', encoding='utf-8-sig') as f:  # utf-8-sigè‡ªåŠ¨ç§»é™¤BOM
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                env_vars[key.strip()] = value.strip()  # æ¸…ç†ç©ºæ ¼
except Exception as e:
    print(f"âŒ Error reading .env file: {e}")
    exit(1)

SUPABASE_URL = env_vars.get("PUBLIC_SUPABASE_URL")
SUPABASE_KEY = env_vars.get("PUBLIC_SUPABASE_ANON_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print(f"âŒ Error: Supabase credentials not found in .env")
    print(f"   Found keys: {list(env_vars.keys())}")
    exit(1)

# Supabase REST API endpoint
REST_URL = f"{SUPABASE_URL}/rest/v1/lawsuits"
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json",
    "Prefer": "return=minimal"
}

# CourtListener API with Token
COURTLISTENER_API = "https://www.courtlistener.com/api/rest/v3/search/"
COURTLISTENER_TOKEN = "7f4374db0b69b37c02779dd59ed9c3b0fb90883d"
COURTLISTENER_HEADERS = {
    "Authorization": f"Token {COURTLISTENER_TOKEN}",
    "User-Agent": "GRICH-Legal-Monitor/1.0"
}

KEYWORDS_FILE = r'd:\quicktoolshub\é›·è¾¾ç›‘æ§ã€‚\GRICH\sql\initial_keywords.json'

# â° REQUEST DELAY: é˜²æ­¢APIé™æµ
REQUEST_DELAY_SECONDS = 8  # æ¯ä¸ªå“ç‰Œé—´éš”8ç§’,é¿å…403é”™è¯¯

def read_keywords():
    try:
        with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f:
            brands = json.load(f)
        return brands if isinstance(brands, list) else []
    except Exception as e:
        print(f"âŒ Error reading keywords: {e}")
        return []

def check_duplicate(brand_name, case_number):
    """
    ğŸ” å»é‡é€»è¾‘: æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥æ¡ˆä»¶
    """
    try:
        # æŸ¥è¯¢æ•°æ®åº“,æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒçš„brand_nameå’Œcase_number
        query_url = f"{REST_URL}?brand_name=eq.{brand_name}&case_number=eq.{case_number}"
        response = requests.get(query_url, headers=HEADERS, timeout=10)
        
        if response.status_code == 200:
            existing_records = response.json()
            if existing_records and len(existing_records) > 0:
                return True  # å·²å­˜åœ¨
        return False  # ä¸å­˜åœ¨
    except Exception as e:
        print(f"  âš ï¸ Error checking duplicate: {e}")
        return False  # å‡ºé”™æ—¶å‡è®¾ä¸å­˜åœ¨,å…è®¸æ’å…¥

def fetch_real_lawsuits(brand_name):
    """
    Query CourtListener's API for real trademark lawsuits.
    """
    try:
        # Search query: brand name + trademark keywords
        query = f'"{brand_name}" AND (trademark OR counterfeiting OR "intellectual property")'
        
        params = {
            'q': query,
            'type': 'r',  # Dockets (case records)
            'order_by': 'dateFiled desc',  # Most recent first
            'court': 'ilnd',  # N.D. Illinois (known for SAD cases)
            'filed_after': '2024-01-01'  # Recent cases only
        }
        
        print(f"  ğŸ” Querying CourtListener for: {brand_name}")
        response = requests.get(COURTLISTENER_API, params=params, headers=COURTLISTENER_HEADERS, timeout=15)
        
        if response.status_code == 403:
            print(f"  ğŸš« 403 Forbidden - Rate limited. Waiting 15 seconds...")
            time.sleep(15)  # é¢å¤–ç­‰å¾…
            return None
        
        if response.status_code != 200:
            print(f"  âš ï¸ CourtListener returned status {response.status_code}")
            return None
        
        data = response.json()
        results = data.get('results', [])
        
        if not results:
            print(f"  âšª No recent lawsuits found")
            return None
        
        # Parse first matching case
        case = results[0]
        
        # Calculate risk score based on case status
        risk_score = 70  # Base score
        case_name = case.get('caseName', '').lower()
        
        if 'tro' in case_name or 'temporary restraining' in case_name:
            risk_score = 95
        elif 'preliminary injunction' in case_name:
            risk_score = 90
        elif 'motion to dismiss' in case_name:
            risk_score = 75
        
        return {
            "brand_name": brand_name,
            "case_number": case.get('docketNumber', 'Unknown'),
            "plaintiff": case.get('caseName', '').split(' v. ')[0] if ' v. ' in case.get('caseName', '') else brand_name,
            "court": case.get('court', 'N.D. Illinois'),
            "filed_date": case.get('dateFiled', datetime.now().strftime('%Y-%m-%d')),
            "status": "Active Litigation",
            "risk_score": risk_score,
            "raw_data_url": f"https://www.courtlistener.com{case.get('absolute_url', '')}"
        }
        
    except requests.Timeout:
        print(f"  â±ï¸ Timeout querying CourtListener")
        return None
    except Exception as e:
        print(f"  âŒ Error fetching data: {e}")
        return None

def seed_database():
    print(f"ğŸ”Œ Connecting to Supabase: {SUPABASE_URL[:30]}...")
    print(f"ğŸ“¡ Using CourtListener API with Token")
    print(f"â° Request delay: {REQUEST_DELAY_SECONDS} seconds per brand\n")
    
    keywords = read_keywords()
    print(f"ğŸ“– Found {len(keywords)} brands to monitor\n")
    
    success_count = 0
    duplicate_count = 0
    failed_count = 0
    
    for index, brand in enumerate(keywords, 1):
        print(f"-----------------------------------")
        print(f"ğŸš€ Processing [{index}/{len(keywords)}]: {brand}")
        
        # Fetch REAL data from CourtListener
        lawsuit_data = fetch_real_lawsuits(brand)
        
        if lawsuit_data:
            # ğŸ” å»é‡æ£€æŸ¥
            is_duplicate = check_duplicate(lawsuit_data['brand_name'], lawsuit_data['case_number'])
            
            if is_duplicate:
                print(f"  â­ï¸ DUPLICATE SKIPPED: {brand} - Case {lawsuit_data['case_number']} already exists")
                duplicate_count += 1
            else:
                try:
                    response = requests.post(REST_URL, headers=HEADERS, json=lawsuit_data)
                    if response.status_code in [200, 201]:
                        print(f"  âœ… NEW DATA INSERTED: {brand}")
                        print(f"     Risk: {lawsuit_data['risk_score']}, Case: {lawsuit_data['case_number']}")
                        success_count += 1
                    else:
                        print(f"  âŒ Failed to insert: {response.text[:100]}")
                        failed_count += 1
                except Exception as e:
                    print(f"  âŒ Database error: {e}")
                    failed_count += 1
        else:
            print(f"  âšª No data available")
            failed_count += 1
        
        # â° è¯·æ±‚å»¶è¿Ÿ: é¿å…APIé™æµ
        if index < len(keywords):  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
            print(f"  â³ Waiting {REQUEST_DELAY_SECONDS} seconds before next request...")
            time.sleep(REQUEST_DELAY_SECONDS)
    
    print("\n" + "="*60)
    print(f"ğŸ‰ Seeding Complete!")
    print(f"ğŸ“Š Results:")
    print(f"   âœ… Successfully inserted: {success_count}")
    print(f"   â­ï¸ Duplicates skipped: {duplicate_count}")
    print(f"   âŒ Failed/No data: {failed_count}")
    print(f"   ğŸ“ˆ Total processed: {len(keywords)}")
    print(f"\nğŸŒ Visit: https://jaxfamlaw.com/compliance/Nike")
    print("="*60)

if __name__ == "__main__":
    seed_database()
