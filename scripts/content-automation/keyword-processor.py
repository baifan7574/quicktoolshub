#!/usr/bin/env python3
"""
å…³é”®è¯å¤„ç†å™¨
åŠŸèƒ½ï¼šå¤„ç†ä»Google Keyword Plannerç­‰å·¥å…·æ‹‰å–çš„å…³é”®è¯æ•°æ®
"""

import pandas as pd
import json
import os
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class KeywordProcessor:
    def __init__(self):
        self.min_volume = int(os.getenv('MIN_SEARCH_VOLUME', 100))
        self.max_volume = int(os.getenv('MAX_SEARCH_VOLUME', 5000))
        self.max_competition = os.getenv('MAX_COMPETITION', 'medium')
        
        # å·¥å…·å…³é”®è¯æ˜ å°„
        self.tool_keywords = {
            'pdf-merger': ['merge pdf', 'combine pdf', 'pdf merger'],
            'pdf-splitter': ['split pdf', 'divide pdf', 'pdf splitter'],
            'pdf-compressor': ['compress pdf', 'reduce pdf size', 'pdf compressor'],
            'pdf-to-word': ['pdf to word', 'convert pdf to word', 'pdf word converter'],
            'image-compressor': ['compress image', 'reduce image size', 'image optimizer'],
            'image-resizer': ['resize image', 'change image size', 'image resizer'],
            'image-converter': ['convert image', 'image format converter', 'change image format'],
            'background-remover': ['remove background', 'transparent background', 'background remover'],
            'word-counter': ['word counter', 'count words', 'character counter'],
            'text-case-converter': ['text case converter', 'uppercase lowercase', 'text transformer'],
            'lorem-ipsum-generator': ['lorem ipsum', 'placeholder text', 'dummy text'],
            'json-formatter': ['json formatter', 'format json', 'json beautifier'],
            'base64-encoder': ['base64 encode', 'base64 decoder', 'base64 converter'],
            'url-encoder': ['url encode', 'url decoder', 'url encoder'],
        }
        
        # æ–‡ç« ç±»å‹åˆ¤æ–­è§„åˆ™
        self.article_type_patterns = {
            'how-to': ['how to', 'how do', 'tutorial', 'guide', 'step by step'],
            'comparison': ['vs', 'versus', 'compare', 'comparison', 'difference'],
            'list': ['best', 'top', '10', '5', 'list', 'review'],
            'question': ['what is', 'why', 'when', 'where', 'can i', 'should i'],
        }
    
    def load_keywords(self, file_path: str) -> pd.DataFrame:
        """åŠ è½½å…³é”®è¯æ–‡ä»¶ï¼ˆCSVæˆ–JSONï¼‰"""
        file_path = Path(file_path)
        
        if file_path.suffix == '.csv':
            df = pd.read_csv(file_path)
        elif file_path.suffix == '.json':
            df = pd.read_json(file_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
        
        return df
    
    def filter_keywords(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç­›é€‰æœ‰æ•ˆå…³é”®è¯"""
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_columns = ['keyword', 'search_volume', 'competition']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
        
        # ç­›é€‰è§„åˆ™
        filtered = df[
            (df['search_volume'] >= self.min_volume) &
            (df['search_volume'] <= self.max_volume) &
            (df['competition'].isin(['low', 'medium']))
        ].copy()
        
        return filtered
    
    def classify_keyword(self, keyword: str) -> dict:
        """åˆ†ç±»å…³é”®è¯ï¼šæ–‡ç« ç±»å‹ã€ç›®æ ‡å·¥å…·"""
        keyword_lower = keyword.lower()
        
        # åˆ¤æ–­æ–‡ç« ç±»å‹
        article_type = 'how-to'  # é»˜è®¤
        for type_name, patterns in self.article_type_patterns.items():
            if any(pattern in keyword_lower for pattern in patterns):
                article_type = type_name
                break
        
        # åŒ¹é…ç›®æ ‡å·¥å…·
        target_tool = None
        for tool_slug, keywords_list in self.tool_keywords.items():
            if any(kw in keyword_lower for kw in keywords_list):
                target_tool = tool_slug
                break
        
        # åˆ¤æ–­åˆ†ç±»
        category = None
        if 'pdf' in keyword_lower:
            category = 'PDF Tools'
        elif 'image' in keyword_lower or 'photo' in keyword_lower:
            category = 'Image Tools'
        elif 'text' in keyword_lower or 'word' in keyword_lower:
            category = 'Text Tools'
        elif 'json' in keyword_lower or 'code' in keyword_lower or 'developer' in keyword_lower:
            category = 'Developer Tools'
        
        return {
            'article_type': article_type,
            'target_tool': target_tool,
            'category': category
        }
    
    def calculate_priority(self, row: pd.Series) -> float:
        """è®¡ç®—å…³é”®è¯ä¼˜å…ˆçº§"""
        # ä¼˜å…ˆçº§ = æœç´¢é‡ / ç«äº‰åº¦ç³»æ•°
        competition_scores = {'low': 1.0, 'medium': 0.7, 'high': 0.3}
        competition_score = competition_scores.get(row['competition'], 0.5)
        
        priority = row['search_volume'] * competition_score
        
        # å¦‚æœæœ‰å·¥å…·åŒ¹é…ï¼Œæé«˜ä¼˜å…ˆçº§
        classification = self.classify_keyword(row['keyword'])
        if classification['target_tool']:
            priority *= 1.2
        
        return priority
    
    def process(self, input_file: str, output_file: str = None) -> pd.DataFrame:
        """å¤„ç†å…³é”®è¯ï¼šåŠ è½½ã€ç­›é€‰ã€åˆ†ç±»ã€æ’åº"""
        print(f"ğŸ“¥ åŠ è½½å…³é”®è¯æ–‡ä»¶: {input_file}")
        df = self.load_keywords(input_file)
        print(f"   åŸå§‹å…³é”®è¯æ•°é‡: {len(df)}")
        
        print(f"ğŸ” ç­›é€‰å…³é”®è¯...")
        df_filtered = self.filter_keywords(df)
        print(f"   ç­›é€‰åæ•°é‡: {len(df_filtered)}")
        
        print(f"ğŸ·ï¸ åˆ†ç±»å…³é”®è¯...")
        classifications = df_filtered['keyword'].apply(self.classify_keyword)
        df_filtered['article_type'] = classifications.apply(lambda x: x['article_type'])
        df_filtered['target_tool'] = classifications.apply(lambda x: x['target_tool'])
        df_filtered['category'] = classifications.apply(lambda x: x['category'])
        
        print(f"ğŸ“Š è®¡ç®—ä¼˜å…ˆçº§...")
        df_filtered['priority'] = df_filtered.apply(self.calculate_priority, axis=1)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        df_filtered = df_filtered.sort_values('priority', ascending=False)
        
        # æ·»åŠ çŠ¶æ€åˆ—
        df_filtered['status'] = 'pending'
        
        # ä¿å­˜ç»“æœ
        if output_file:
            output_path = Path(output_file)
            if output_path.suffix == '.csv':
                df_filtered.to_csv(output_file, index=False)
            elif output_path.suffix == '.json':
                df_filtered.to_json(output_file, orient='records', indent=2)
            print(f"ğŸ’¾ ä¿å­˜å¤„ç†ç»“æœ: {output_file}")
        
        print(f"âœ… å¤„ç†å®Œæˆï¼")
        print(f"   æœ€ç»ˆå…³é”®è¯æ•°é‡: {len(df_filtered)}")
        print(f"   æ–‡ç« ç±»å‹åˆ†å¸ƒ:")
        print(df_filtered['article_type'].value_counts().to_string())
        
        return df_filtered


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python keyword-processor.py <è¾“å…¥æ–‡ä»¶> [è¾“å‡ºæ–‡ä»¶]")
        print("ç¤ºä¾‹: python keyword-processor.py ../data/keywords-raw.csv ../data/keywords-processed.json")
        sys.exit(1)
    
    processor = KeywordProcessor()
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = processor.process(input_file, output_file)
    print("\nå‰10ä¸ªé«˜ä¼˜å…ˆçº§å…³é”®è¯:")
    print(result[['keyword', 'search_volume', 'competition', 'priority', 'article_type', 'target_tool']].head(10).to_string())

