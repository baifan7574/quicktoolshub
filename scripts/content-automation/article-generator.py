#!/usr/bin/env python3
"""
æ–‡ç« ç”Ÿæˆå™¨
åŠŸèƒ½ï¼šä½¿ç”¨AIç”ŸæˆSEOä¼˜åŒ–çš„æ–‡ç« å†…å®¹
"""

import os
import json
import re
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime

# å°è¯•å¯¼å…¥AIåº“
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

load_dotenv()

class ArticleGenerator:
    def __init__(self):
        self.openai_key = os.getenv('OPENAI_API_KEY')
        self.anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        self.model = os.getenv('AI_MODEL', 'gpt-4o-mini')
        self.default_length = int(os.getenv('DEFAULT_ARTICLE_LENGTH', 1500))
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        if self.openai_key and OPENAI_AVAILABLE:
            self.ai_client = OpenAI(api_key=self.openai_key)
            self.ai_provider = 'openai'
        elif self.anthropic_key and ANTHROPIC_AVAILABLE:
            self.ai_client = anthropic.Anthropic(api_key=self.anthropic_key)
            self.ai_provider = 'anthropic'
        else:
            raise ValueError("éœ€è¦é…ç½® OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY")
    
    def generate_slug(self, title: str) -> str:
        """ç”ŸæˆURLå‹å¥½çš„slug"""
        slug = title.lower()
        slug = re.sub(r'[^a-z0-9\s-]', '', slug)
        slug = re.sub(r'\s+', '-', slug)
        slug = re.sub(r'-+', '-', slug)
        slug = slug.strip('-')
        return slug
    
    def generate_outline(self, keyword: str, article_type: str, target_tool: str = None) -> str:
        """ç”Ÿæˆæ–‡ç« å¤§çº²"""
        if article_type == 'how-to':
            prompt = f"""ä¸ºå…³é”®è¯ "{keyword}" åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚

æ–‡ç« ç±»å‹ï¼šHow-toæ•™ç¨‹
ç›®æ ‡å·¥å…·ï¼š{target_tool if target_tool else 'é€šç”¨'}

è¦æ±‚ï¼š
1. åŒ…å«æ¸…æ™°çš„æ­¥éª¤è¯´æ˜
2. åŒ…å«å·¥å…·æ¨èéƒ¨åˆ†
3. åŒ…å«å¸¸è§é—®é¢˜è§£ç­”
4. åŒ…å«æœ€ä½³å®è·µå»ºè®®

è¯·ä»¥Markdownæ ¼å¼è¾“å‡ºå¤§çº²ï¼ŒåŒ…å«ï¼š
- æ ‡é¢˜
- å¼•è¨€
- ä¸»è¦æ­¥éª¤ï¼ˆè‡³å°‘5æ­¥ï¼‰
- å·¥å…·æ¨è
- å¸¸è§é—®é¢˜
- æ€»ç»“"""
        
        elif article_type == 'comparison':
            prompt = f"""ä¸ºå…³é”®è¯ "{keyword}" åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚

æ–‡ç« ç±»å‹ï¼šå¯¹æ¯”æ–‡ç« 

è¦æ±‚ï¼š
1. å¯¹æ¯”ä¸åŒå·¥å…·/æ–¹æ³•
2. åˆ—å‡ºä¼˜ç¼ºç‚¹
3. æä¾›ä½¿ç”¨å»ºè®®
4. åŒ…å«æ¨è

è¯·ä»¥Markdownæ ¼å¼è¾“å‡ºå¤§çº²ã€‚"""
        
        elif article_type == 'list':
            prompt = f"""ä¸ºå…³é”®è¯ "{keyword}" åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚

æ–‡ç« ç±»å‹ï¼šåˆ—è¡¨æ–‡ç« 

è¦æ±‚ï¼š
1. åˆ—å‡º10ä¸ªæœ€ä½³å·¥å…·/æ–¹æ³•
2. æ¯ä¸ªå·¥å…·åŒ…å«ç®€ä»‹ã€ä¼˜ç¼ºç‚¹ã€ä½¿ç”¨åœºæ™¯
3. åŒ…å«æ€»ç»“å’Œæ¨è

è¯·ä»¥Markdownæ ¼å¼è¾“å‡ºå¤§çº²ã€‚"""
        
        else:  # question
            prompt = f"""ä¸ºå…³é”®è¯ "{keyword}" åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚

æ–‡ç« ç±»å‹ï¼šé—®é¢˜è§£ç­”

è¦æ±‚ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜
2. æä¾›è¯¦ç»†è§£é‡Š
3. åŒ…å«ç›¸å…³å·¥å…·æ¨è
4. åŒ…å«å®é™…æ¡ˆä¾‹

è¯·ä»¥Markdownæ ¼å¼è¾“å‡ºå¤§çº²ã€‚"""
        
        return self._call_ai(prompt)
    
    def generate_article(self, keyword: str, outline: str, article_type: str, 
                        target_tool: str = None, word_count: int = None) -> str:
        """ç”Ÿæˆå®Œæ•´æ–‡ç« """
        word_count = word_count or self.default_length
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹å¤§çº²ï¼Œå†™ä¸€ç¯‡å…³äº "{keyword}" çš„å®Œæ•´æ–‡ç« ã€‚

æ–‡ç« ç±»å‹ï¼š{article_type}
ç›®æ ‡å­—æ•°ï¼š{word_count}å­—
ç›®æ ‡å·¥å…·ï¼š{target_tool if target_tool else 'é€šç”¨'}

å¤§çº²ï¼š
{outline}

è¦æ±‚ï¼š
1. æ–‡ç« å¿…é¡»å®Œæ•´ã€è¯¦ç»†ã€æœ‰ä»·å€¼
2. è‡ªç„¶èå…¥å…³é”®è¯ï¼ˆä¸è¦å †ç Œï¼‰
3. åŒ…å«å®é™…ä½¿ç”¨æ­¥éª¤å’Œç¤ºä¾‹
4. å¦‚æœæåˆ°å·¥å…·ï¼Œè¯·ä½¿ç”¨è‡ªç„¶çš„æ–¹å¼æ¨è
5. ä½¿ç”¨Markdownæ ¼å¼
6. åŒ…å«æ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ç­‰
7. ç¡®ä¿æ–‡ç« é•¿åº¦è¾¾åˆ°ç›®æ ‡å­—æ•°

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚"""
        
        return self._call_ai(prompt)
    
    def generate_title(self, keyword: str, article_type: str) -> str:
        """ç”ŸæˆSEOä¼˜åŒ–çš„æ ‡é¢˜"""
        prompt = f"""ä¸ºå…³é”®è¯ "{keyword}" ç”Ÿæˆä¸€ä¸ªSEOä¼˜åŒ–çš„æ–‡ç« æ ‡é¢˜ã€‚

æ–‡ç« ç±»å‹ï¼š{article_type}

è¦æ±‚ï¼š
1. æ ‡é¢˜å¿…é¡»åŒ…å«å…³é”®è¯
2. æ ‡é¢˜é•¿åº¦ï¼š50-60å­—ç¬¦
3. æ ‡é¢˜è¦æœ‰å¸å¼•åŠ›
4. å¯ä»¥åŒ…å«å¹´ä»½ï¼ˆ2024ï¼‰
5. å¯ä»¥åŒ…å«"Free"ã€"Complete Guide"ç­‰è¯

åªè¾“å‡ºæ ‡é¢˜ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        
        title = self._call_ai(prompt).strip()
        # æ¸…ç†æ ‡é¢˜
        title = re.sub(r'^["\']|["\']$', '', title)
        return title
    
    def generate_excerpt(self, content: str, max_length: int = 155) -> str:
        """ä»æ–‡ç« å†…å®¹ç”Ÿæˆæ‘˜è¦"""
        # æå–ç¬¬ä¸€æ®µæˆ–å‰å‡ å¥è¯
        paragraphs = content.split('\n\n')
        excerpt = paragraphs[0] if paragraphs else content[:200]
        
        # æ¸…ç†Markdownæ ‡è®°
        excerpt = re.sub(r'#+\s*', '', excerpt)
        excerpt = re.sub(r'\*\*([^*]+)\*\*', r'\1', excerpt)
        excerpt = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', excerpt)
        
        # æˆªæ–­åˆ°åˆé€‚é•¿åº¦
        if len(excerpt) > max_length:
            excerpt = excerpt[:max_length].rsplit(' ', 1)[0] + '...'
        
        return excerpt.strip()
    
    def _call_ai(self, prompt: str) -> str:
        """è°ƒç”¨AI API"""
        if self.ai_provider == 'openai':
            response = self.ai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SEOå†…å®¹å†™ä½œä¸“å®¶ï¼Œæ“…é•¿å†™é«˜è´¨é‡ã€SEOå‹å¥½çš„æŠ€æœ¯æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            return response.choices[0].message.content
        
        elif self.ai_provider == 'anthropic':
            response = self.ai_client.messages.create(
                model=self.model if 'claude' in self.model else 'claude-3-haiku-20240307',
                max_tokens=4000,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
    
    def generate(self, keyword_data: dict) -> dict:
        """ç”Ÿæˆå®Œæ•´æ–‡ç« æ•°æ®"""
        keyword = keyword_data['keyword']
        article_type = keyword_data.get('article_type', 'how-to')
        target_tool = keyword_data.get('target_tool')
        
        print(f"ğŸ“ ç”Ÿæˆæ–‡ç« : {keyword}")
        
        # 1. ç”Ÿæˆæ ‡é¢˜
        print("   ç”Ÿæˆæ ‡é¢˜...")
        title = self.generate_title(keyword, article_type)
        
        # 2. ç”Ÿæˆå¤§çº²
        print("   ç”Ÿæˆå¤§çº²...")
        outline = self.generate_outline(keyword, article_type, target_tool)
        
        # 3. ç”Ÿæˆæ–‡ç« 
        print("   ç”Ÿæˆæ–‡ç« å†…å®¹...")
        content = self.generate_article(keyword, outline, article_type, target_tool)
        
        # 4. ç”Ÿæˆæ‘˜è¦
        excerpt = self.generate_excerpt(content)
        
        # 5. ç”Ÿæˆslug
        slug = self.generate_slug(title)
        
        # 6. è®¡ç®—é˜…è¯»æ—¶é•¿ï¼ˆå‡è®¾æ¯åˆ†é’Ÿ200å­—ï¼‰
        word_count = len(content.split())
        reading_time = max(1, word_count // 200)
        
        # 7. æå–æ ‡ç­¾
        tags = self._extract_tags(keyword, article_type, target_tool)
        
        result = {
            'title': title,
            'slug': slug,
            'excerpt': excerpt,
            'content': content,
            'category': keyword_data.get('category'),
            'tags': tags,
            'keywords': [keyword],
            'related_tools': [target_tool] if target_tool else [],
            'reading_time': reading_time,
            'word_count': word_count,
            'article_type': article_type,
            'status': 'generated',
            'created_at': datetime.now().isoformat()
        }
        
        print(f"âœ… æ–‡ç« ç”Ÿæˆå®Œæˆï¼")
        print(f"   æ ‡é¢˜: {title}")
        print(f"   å­—æ•°: {word_count}")
        print(f"   é˜…è¯»æ—¶é•¿: {reading_time}åˆ†é’Ÿ")
        
        return result
    
    def _extract_tags(self, keyword: str, article_type: str, target_tool: str = None) -> list:
        """æå–æ ‡ç­¾"""
        tags = []
        
        # ä»å…³é”®è¯æå–
        if 'pdf' in keyword.lower():
            tags.append('PDF')
        if 'image' in keyword.lower() or 'photo' in keyword.lower():
            tags.append('Image')
        if 'free' in keyword.lower():
            tags.append('Free')
        if 'online' in keyword.lower():
            tags.append('Online')
        
        # æ–‡ç« ç±»å‹æ ‡ç­¾
        tags.append(article_type.replace('-', ' ').title())
        
        # å·¥å…·æ ‡ç­¾
        if target_tool:
            tags.append(target_tool.replace('-', ' ').title())
        
        return list(set(tags))  # å»é‡


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python article-generator.py <å…³é”®è¯JSONæ–‡ä»¶> [è¾“å‡ºç›®å½•]")
        print("ç¤ºä¾‹: python article-generator.py ../data/keywords-processed.json ../data/articles-generated/")
        sys.exit(1)
    
    generator = ArticleGenerator()
    input_file = sys.argv[1]
    output_dir = Path(sys.argv[2]) if len(sys.argv) > 2 else Path('../data/articles-generated')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¯»å–å…³é”®è¯
    with open(input_file, 'r', encoding='utf-8') as f:
        keywords = json.load(f)
    
    # ç”Ÿæˆæ–‡ç« ï¼ˆç¤ºä¾‹ï¼šå‰5ä¸ªï¼‰
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆæ–‡ç« ...")
    for i, keyword_data in enumerate(keywords[:5], 1):
        print(f"\n[{i}/{min(5, len(keywords))}]")
        try:
            article = generator.generate(keyword_data)
            
            # ä¿å­˜æ–‡ç« 
            output_file = output_dir / f"{article['slug']}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(article, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ä¿å­˜æ–‡ç« : {output_file}")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            continue
    
    print(f"\nâœ… å®Œæˆï¼")

